{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca65fcc8",
   "metadata": {},
   "source": [
    "# ðŸ“Š Telco Customer Churn Intelligence Platform (CCIP)\n",
    "### End-to-End ML Project â€” Akeem Asiru\n",
    "\n",
    "This notebook walks through the **full machine learning workflow** behind the Telco Customer Churn Intelligence Platform (CCIP):\n",
    "\n",
    "- Business understanding & problem framing  \n",
    "- Data loading & exploration  \n",
    "- Cleaning & feature engineering  \n",
    "- Model training & evaluation  \n",
    "- Model interpretability (SHAP)  \n",
    "- Saving the production model (`best_churn_model.joblib`)  \n",
    "- Helper functions for **single** and **batch** predictions  \n",
    "\n",
    "> **Author:** Akeem Asiru â€” Machine Learning Engineer  \n",
    "> **Project:** Telco Customer Churn Intelligence Platform (CCIP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4f061b",
   "metadata": {},
   "source": [
    "## 1. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f56fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    RocCurveDisplay,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Optional: SHAP for explainability\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "\n",
    "# Plot style\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# Paths (assumes this notebook lives at project root)\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"Telco-Customer-Churn.csv\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Data path:    {DATA_PATH}\")\n",
    "print(f\"Models dir:   {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca24b26d",
   "metadata": {},
   "source": [
    "## 2. Business Problem Framing\n",
    "\n",
    "**Business question:**  \n",
    "> _Which customers are most likely to churn in the next period, and how can we prioritize retention efforts to reduce churn and protect revenue?_\n",
    "\n",
    "**Key goals:**  \n",
    "- Predict the probability that a given customer will churn.  \n",
    "- Quantify overall churn rate and segment-level churn.  \n",
    "- Provide interpretable drivers of churn using SHAP.  \n",
    "- Enable single-customer and batch predictions for downstream apps (FastAPI, Streamlit, dashboards)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cad828",
   "metadata": {},
   "source": [
    "## 3. Load Telco Churn Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61170687",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df.columns = df.columns.str.strip()  # clean any trailing spaces\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21866cc9",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a8eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns:\\n\", df.columns.tolist())\n",
    "print(\"\\nInfo:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1c43dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn distribution\n",
    "churn_counts = df[\"Churn\"].value_counts()\n",
    "churn_rate = (df[\"Churn\"] == \"Yes\").mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "churn_counts.plot(kind=\"bar\", ax=ax)\n",
    "ax.set_title(f\"Churn Distribution (rate = {churn_rate:.2%})\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0504d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric summary\n",
    "df.describe(include=[np.number]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d1f369",
   "metadata": {},
   "source": [
    "## 5. Data Cleaning & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a263572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean TotalCharges (string with spaces for missing)\n",
    "if \"TotalCharges\" in df.columns:\n",
    "    df[\"TotalCharges\"] = df[\"TotalCharges\"].replace(\" \", np.nan)\n",
    "    df[\"TotalCharges\"] = df[\"TotalCharges\"].astype(float)\n",
    "    mask_missing = df[\"TotalCharges\"].isna()\n",
    "    df.loc[mask_missing, \"TotalCharges\"] = (\n",
    "        df.loc[mask_missing, \"MonthlyCharges\"] * df.loc[mask_missing, \"tenure\"].fillna(0)\n",
    "    )\n",
    "\n",
    "print(\"Missing values after TotalCharges fix:\\n\", df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9742d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary target\n",
    "df[\"ChurnFlag\"] = (df[\"Churn\"] == \"Yes\").astype(int)\n",
    "\n",
    "# Simple feature engineering\n",
    "df[\"MonthlyTenureInteraction\"] = df[\"MonthlyCharges\"] * df[\"tenure\"]\n",
    "df[\"HasMultipleServices\"] = (\n",
    "    (df[\"PhoneService\"] == \"Yes\").astype(int)\n",
    "    + (df[\"InternetService\"] != \"No\").astype(int)\n",
    ")\n",
    "\n",
    "# Drop identifiers\n",
    "drop_cols = [\"customerID\"]\n",
    "for c in drop_cols:\n",
    "    if c in df.columns:\n",
    "        df = df.drop(columns=[c])\n",
    "\n",
    "target_col = \"ChurnFlag\"\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Churn rate:\", y.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8601c27",
   "metadata": {},
   "source": [
    "## 6. Feature Types (Numeric vs Categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87874a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=[\"object\", \"bool\"]).columns.tolist()\n",
    "\n",
    "print(\"Numeric features (\", len(numeric_features), \"):\\n\", numeric_features)\n",
    "print(\"\\nCategorical features (\", len(categorical_features), \"):\\n\", categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71016e60",
   "metadata": {},
   "source": [
    "## 7. Preprocessing Pipeline (ColumnTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a37152",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
    ")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c55185a",
   "metadata": {},
   "source": [
    "## 8. Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996fe8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde27ee4",
   "metadata": {},
   "source": [
    "## 9. Define Candidate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dd9f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\", LogisticRegression(max_iter=1000, n_jobs=-1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf_clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\", RandomForestClassifier(\n",
    "            n_estimators=300,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )),\n",
    "    ]\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": log_reg_clf,\n",
    "    \"Random Forest\": rf_clf,\n",
    "}\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de8739",
   "metadata": {},
   "source": [
    "## 10. Train & Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac2e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary = []\n",
    "\n",
    "for name, pipe in models.items():\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"Training model: {name}\")\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"ROC AUC:  {auc:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "    ax.set_title(f\"Confusion Matrix â€” {name}\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "    RocCurveDisplay.from_predictions(y_test, y_proba)\n",
    "    plt.title(f\"ROC Curve â€” {name}\")\n",
    "    plt.show()\n",
    "\n",
    "    results_summary.append({\n",
    "        \"model\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"roc_auc\": auc,\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_summary).sort_values(\"roc_auc\", ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa26302",
   "metadata": {},
   "source": [
    "## 11. Select Best Model & Save to `models/best_churn_model.joblib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9024b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = results_df.iloc[0]\n",
    "best_name = best_row[\"model\"]\n",
    "print(\"\\nðŸ† Best model:\", best_name)\n",
    "\n",
    "best_model = models[best_name]\n",
    "\n",
    "# Optionally refit on full data (train + test)\n",
    "best_model.fit(X, y)\n",
    "\n",
    "model_path = MODELS_DIR / \"best_churn_model.joblib\"\n",
    "joblib.dump(best_model, model_path)\n",
    "\n",
    "print(f\"âœ… Saved best model pipeline to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9671972f",
   "metadata": {},
   "source": [
    "## 12. Single-Customer Prediction Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c59533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_customer = {\n",
    "    \"gender\": \"Female\",\n",
    "    \"SeniorCitizen\": 0,\n",
    "    \"Partner\": \"Yes\",\n",
    "    \"Dependents\": \"No\",\n",
    "    \"tenure\": 5,\n",
    "    \"PhoneService\": \"Yes\",\n",
    "    \"MultipleLines\": \"No\",\n",
    "    \"InternetService\": \"Fiber optic\",\n",
    "    \"OnlineSecurity\": \"No\",\n",
    "    \"OnlineBackup\": \"No\",\n",
    "    \"DeviceProtection\": \"No\",\n",
    "    \"TechSupport\": \"No\",\n",
    "    \"StreamingTV\": \"Yes\",\n",
    "    \"StreamingMovies\": \"Yes\",\n",
    "    \"Contract\": \"Month-to-month\",\n",
    "    \"PaperlessBilling\": \"Yes\",\n",
    "    \"PaymentMethod\": \"Electronic check\",\n",
    "    \"MonthlyCharges\": 80.5,\n",
    "    \"TotalCharges\": 400.0,\n",
    "    \"MonthlyTenureInteraction\": 80.5 * 5,\n",
    "    \"HasMultipleServices\": 2,\n",
    "}\n",
    "\n",
    "example_df = pd.DataFrame([example_customer])\n",
    "proba = best_model.predict_proba(example_df)[0, 1]\n",
    "label = \"Churn\" if proba >= 0.5 else \"No Churn\"\n",
    "\n",
    "print(f\"Predicted churn probability: {proba:.3f}\")\n",
    "print(f\"Predicted label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109d2fe8",
   "metadata": {},
   "source": [
    "## 13. Batch Prediction Helper (for CSV Files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c198b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch_prediction(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Run churn predictions on a batch of customers.\n",
    "    Expects raw Telco-like schema, including:\n",
    "    - tenure, MonthlyCharges, TotalCharges\n",
    "    - service features\n",
    "    - but will ignore 'customerID' and 'Churn' if present.\n",
    "    \"\"\"\n",
    "    df_batch = input_df.copy()\n",
    "\n",
    "    # Clean TotalCharges\n",
    "    if \"TotalCharges\" in df_batch.columns:\n",
    "        df_batch[\"TotalCharges\"] = df_batch[\"TotalCharges\"].replace(\" \", np.nan)\n",
    "        df_batch[\"TotalCharges\"] = df_batch[\"TotalCharges\"].astype(float)\n",
    "        mask_missing = df_batch[\"TotalCharges\"].isna()\n",
    "        df_batch.loc[mask_missing, \"TotalCharges\"] = (\n",
    "            df_batch.loc[mask_missing, \"MonthlyCharges\"] * df_batch.loc[mask_missing, \"tenure\"].fillna(0)\n",
    "        )\n",
    "\n",
    "    # Feature engineering\n",
    "    df_batch[\"MonthlyTenureInteraction\"] = df_batch[\"MonthlyCharges\"] * df_batch[\"tenure\"].fillna(0)\n",
    "    df_batch[\"HasMultipleServices\"] = (\n",
    "        (df_batch[\"PhoneService\"] == \"Yes\").astype(int)\n",
    "        + (df_batch[\"InternetService\"] != \"No\").astype(int)\n",
    "    )\n",
    "\n",
    "    # Drop unwanted columns if present\n",
    "    for col in [\"Churn\", \"ChurnFlag\", \"customerID\"]:\n",
    "        if col in df_batch.columns:\n",
    "            df_batch = df_batch.drop(columns=[col])\n",
    "\n",
    "    # Predict\n",
    "    proba = best_model.predict_proba(df_batch)[:, 1]\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "    out_df = df_batch.copy()\n",
    "    out_df[\"churn_prediction\"] = pred\n",
    "    out_df[\"churn_probability\"] = proba\n",
    "\n",
    "    return out_df\n",
    "\n",
    "# Quick smoke test on first 5 rows (dropping target)\n",
    "batch_test = run_batch_prediction(df.drop(columns=[\"Churn\", \"ChurnFlag\"], errors=\"ignore\").head(5))\n",
    "batch_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7e1eb9",
   "metadata": {},
   "source": [
    "## 14. Model Explainability with SHAP (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f660651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP_AVAILABLE:\n",
    "    print(\"SHAP is available â€” computing global feature importance on a sample...\")\n",
    "    preprocess_step = best_model.named_steps[\"preprocess\"]\n",
    "    model_step = best_model.named_steps[\"model\"]\n",
    "\n",
    "    X_sample = X.sample(300, random_state=42)\n",
    "    X_trans = preprocess_step.transform(X_sample)\n",
    "\n",
    "    # Use TreeExplainer for tree-based models, otherwise generic Explainer\n",
    "    if isinstance(model_step, RandomForestClassifier):\n",
    "        explainer = shap.TreeExplainer(model_step)\n",
    "        shap_values = explainer(X_trans)\n",
    "    else:\n",
    "        explainer = shap.Explainer(model_step, X_trans)\n",
    "        shap_values = explainer(X_trans)\n",
    "\n",
    "    shap.summary_plot(shap_values, X_trans, show=True)\n",
    "else:\n",
    "    print(\"SHAP is not installed. Run `pip install shap` to enable explainability plots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49034b1",
   "metadata": {},
   "source": [
    "## 15. Next Steps & Integration\n",
    "\n",
    "This notebook produces a production-ready model artifact:\n",
    "\n",
    "- `models/best_churn_model.joblib`\n",
    "\n",
    "This model is:\n",
    "- Loaded by the **FastAPI** backend for real-time scoring.  \n",
    "- Used by the **Streamlit** dashboard to power:\n",
    "  - Single customer predictions  \n",
    "  - Batch predictions  \n",
    "  - Advanced KMeans segmentation  \n",
    "  - Churn risk insights  \n",
    "\n",
    "**Deployed system components (outside of this notebook):**\n",
    "- FastAPI model-serving API  \n",
    "- Streamlit executive dashboard  \n",
    "- Prometheus & Grafana for monitoring  \n",
    "- Docker + Nginx for containerized deployment  \n",
    "- (Planned) GitHub Actions CI/CD for auto-deploys to EC2  \n",
    "\n",
    "> This notebook is the **analytical heart** of the Telco Customer Churn Intelligence Platform (CCIP) built by **Akeem Asiru**.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
